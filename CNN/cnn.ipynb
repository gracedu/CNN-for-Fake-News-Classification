{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tpg3sL0TQk2_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Preprocess data\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction import text\n",
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "#from nltk.tokenize import word_tokenize\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np\n",
        "\n",
        "# fake is 0, true is 1\n",
        "#load the data using pandas\n",
        "x_train = pd.read_csv(\"x_train.csv\", index_col=[0])\n",
        "x_val = pd.read_csv(\"x_val.csv\", index_col=[0])\n",
        "\n",
        "#lowercase\n",
        "x_train[\"content\"] = x_train[\"content\"].str.lower()\n",
        "x_val[\"content\"] = x_val[\"content\"].str.lower()\n",
        "\n",
        "#remove puctuation and stop word\n",
        "stop = text.ENGLISH_STOP_WORDS\n",
        "x_train[\"content\"] = x_train[\"content\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "x_val[\"content\"] = x_val[\"content\"].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop)]))\n",
        "\n",
        "\n",
        "x_train[\"content\"] = x_train[\"content\"].str.replace('[^\\w\\s]','')\n",
        "x_val[\"content\"] = x_val[\"content\"].str.replace('[^\\w\\s]','')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IS2IHmUro3Zg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#stemming process\n",
        "#stemmer reference: https://stackoverflow.com/questions/43795310/apply-porters-stemmer-to-a-pandas-column-for-each-word\n",
        "\n",
        "# porter_stemmer = PorterStemmer()\n",
        "\n",
        "# def stem(sentence):\n",
        "#     tokens = sentence.split()\n",
        "#     stemmed_tokens = [porter_stemmer.stem(token) for token in tokens]\n",
        "#     return ' '.join(stemmed_tokens)\n",
        "\n",
        "\n",
        "# x_train[\"content\"] = x_train[\"content\"].apply(stem)\n",
        "# x_val[\"content\"] = x_val[\"content\"].apply(stem)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TI-xPbnGtyfV",
        "colab_type": "code",
        "outputId": "07f6a191-1706-4642-dfd7-d28c187f9402",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "import nltk as nltk\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/wordnet.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CHynb4mZrdOD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#lemmatization\\\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "\n",
        "lemmatizer = WordNetLemmatizer() \n",
        "\n",
        "def lemma(sentence):\n",
        "    tokens = sentence.split()\n",
        "    lemmaed_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
        "    return ' '.join(lemmaed_tokens)\n",
        "\n",
        "\n",
        "x_train[\"content\"] = x_train[\"content\"].apply(lemma)\n",
        "x_val[\"content\"] = x_val[\"content\"].apply(lemma)\n",
        "\n",
        "xx_train = x_train[\"content\"]\n",
        "xx_val = x_val[\"content\"]\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tmDJHjoQLyUj",
        "colab_type": "code",
        "outputId": "79b6f90f-ac71-43e0-88eb-164a6c2be21a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "x_val[\"content\"]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       moody downgrade uk rating brexit growth fearsl...\n",
              "1       damaged new zealand fuel pipeline restarted su...\n",
              "2       china say ban petroleum export north koreashan...\n",
              "3       u challenged rising north korea tension russia...\n",
              "4       temper fray search survivor wind mexico quakem...\n",
              "                              ...                        \n",
              "4485    mcpain john mccain furious iran treated sailor...\n",
              "4486    justice yahoo settle email privacy classaction...\n",
              "4487    sunnistan allied safe zone plan territorial bo...\n",
              "4488    blow 700 million al jazeera america finally ca...\n",
              "4489    10 u navy sailor held iranian military sign ne...\n",
              "Name: content, Length: 4490, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fh_YdTxLqhiH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#tokenizer and padding\n",
        "tokenizer = Tokenizer(num_words=50000, oov_token=None)\n",
        "tokenizer.fit_on_texts(xx_train)\n",
        "word_index = tokenizer.word_index\n",
        "xx_train = tokenizer.texts_to_sequences(xx_train) \n",
        "xx_val = tokenizer.texts_to_sequences(xx_val)\n",
        "maxlen = max([len(x) for x in xx_train]) \n",
        "\n",
        "xx_train = pad_sequences(xx_train, maxlen=maxlen)\n",
        "xx_val = pad_sequences(xx_val, maxlen=maxlen)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M0Ux23RXYQw",
        "colab_type": "code",
        "outputId": "bb8e174e-ab17-470d-c6cb-111f07235daf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.layers import Activation, Input, Embedding, Reshape, Concatenate, Flatten, Dropout, Dense, Conv1D\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.optimizers import Adam\n",
        "from keras import optimizers\n",
        "from keras.layers import Embedding\n",
        "import os\n",
        "from keras import regularizers\n",
        "from keras import Sequential\n",
        "from keras.layers import MaxPooling1D\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "\n",
        "\n",
        "#reference of cnn: https://www.kaggle.com/au1206/text-classification-using-cnn\n",
        "#reference: https://keras.io/examples/imdb_cnn/\n",
        "# we have xx_train, y_train, xx_val, y_val\n",
        "y_train =  pd.read_csv(\"y_train.csv\")\n",
        "y_val = pd.read_csv(\"y_val.csv\")\n",
        "y_train = y_train[\"label\"]\n",
        "y_val = y_val[\"label\"]\n",
        "y_train = to_categorical(y_train)\n",
        "y_val = to_categorical(y_val)\n",
        "\n",
        "\n",
        "batch_size = 32\n",
        "embedding_dims = 100\n",
        "filters = 32\n",
        "kernel_size = 5\n",
        "\n",
        "epochs = 50\n",
        "\n",
        "embedding_layer = Embedding(50001, 100,input_length=maxlen)\n",
        "\n",
        "\n",
        "model = Sequential()\n",
        "#model.add(Reshape([100], input_shape=[100]))\n",
        "model.add(embedding_layer)\n",
        "#model.add(Reshape((100,100)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "model.add(Conv1D(filters, kernel_size, padding='valid', activation='elu', activity_regularizer=regularizers.l2(0.01)))\n",
        "model.add(MaxPooling1D())\n",
        "#model.add(Conv1D(filters, kernel_size, padding='valid', activation='elu', activity_regularizer=regularizers.l2(0.01)))\n",
        "#model.add(MaxPooling1D())\n",
        "\n",
        "model.add(Flatten())\n",
        "\n",
        "model.add(Dense(2, activation='elu'))\n",
        "\n",
        "model.add(Dropout(0.2))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "model.add(Dense(2, activation='sigmoid'))\n",
        "adam = optimizers.Adam(lr=0.001)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=adam, metrics=['accuracy'])\n",
        "#model.fit(xx_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(xx_val, y_val), shuffle=True)\n",
        "\n",
        "#model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtxoMZcOL58f",
        "colab_type": "code",
        "outputId": "6e30604f-3df7-49a8-d5e5-a012c990edb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(xx_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(xx_val, y_val), shuffle=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/indexed_slices.py:434: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 40408 samples, validate on 4490 samples\n",
            "Epoch 1/50\n",
            "40408/40408 [==============================] - 38s 930us/step - loss: 76.8302 - accuracy: 0.5265 - val_loss: 2.8469 - val_accuracy: 0.4938\n",
            "Epoch 2/50\n",
            "40408/40408 [==============================] - 31s 768us/step - loss: 2.0914 - accuracy: 0.6043 - val_loss: 2.5011 - val_accuracy: 0.9003\n",
            "Epoch 3/50\n",
            "40408/40408 [==============================] - 31s 767us/step - loss: 1.3400 - accuracy: 0.8944 - val_loss: 0.9709 - val_accuracy: 0.9244\n",
            "Epoch 4/50\n",
            "40408/40408 [==============================] - 31s 769us/step - loss: 0.7649 - accuracy: 0.9190 - val_loss: 0.5654 - val_accuracy: 0.9532\n",
            "Epoch 5/50\n",
            "40408/40408 [==============================] - 31s 773us/step - loss: 0.5561 - accuracy: 0.9213 - val_loss: 0.7903 - val_accuracy: 0.8546\n",
            "Epoch 6/50\n",
            "40408/40408 [==============================] - 31s 766us/step - loss: 0.5693 - accuracy: 0.9226 - val_loss: 0.5441 - val_accuracy: 0.9606\n",
            "Epoch 7/50\n",
            "40408/40408 [==============================] - 31s 765us/step - loss: 0.5024 - accuracy: 0.9347 - val_loss: 0.5052 - val_accuracy: 0.9332\n",
            "Epoch 8/50\n",
            "40408/40408 [==============================] - 31s 766us/step - loss: 0.3521 - accuracy: 0.9497 - val_loss: 0.2754 - val_accuracy: 0.9699\n",
            "Epoch 9/50\n",
            "40408/40408 [==============================] - 31s 768us/step - loss: 0.1733 - accuracy: 0.9653 - val_loss: 0.1325 - val_accuracy: 0.9746\n",
            "Epoch 10/50\n",
            "40408/40408 [==============================] - 31s 768us/step - loss: 0.1028 - accuracy: 0.9747 - val_loss: 0.1928 - val_accuracy: 0.9468\n",
            "Epoch 11/50\n",
            "40408/40408 [==============================] - 31s 769us/step - loss: 0.0757 - accuracy: 0.9773 - val_loss: 0.1259 - val_accuracy: 0.9612\n",
            "Epoch 12/50\n",
            "40408/40408 [==============================] - 31s 768us/step - loss: 0.0945 - accuracy: 0.9758 - val_loss: 0.2214 - val_accuracy: 0.9359\n",
            "Epoch 13/50\n",
            "40408/40408 [==============================] - 31s 770us/step - loss: 0.0589 - accuracy: 0.9784 - val_loss: 0.0924 - val_accuracy: 0.9755\n",
            "Epoch 14/50\n",
            "40408/40408 [==============================] - 31s 771us/step - loss: 0.0537 - accuracy: 0.9789 - val_loss: 0.1006 - val_accuracy: 0.9757\n",
            "Epoch 15/50\n",
            "40408/40408 [==============================] - 31s 772us/step - loss: 0.0737 - accuracy: 0.9768 - val_loss: 0.1274 - val_accuracy: 0.9684\n",
            "Epoch 16/50\n",
            "40408/40408 [==============================] - 31s 769us/step - loss: 0.0794 - accuracy: 0.9759 - val_loss: 0.1549 - val_accuracy: 0.9579\n",
            "Epoch 17/50\n",
            "40408/40408 [==============================] - 31s 767us/step - loss: 0.0509 - accuracy: 0.9784 - val_loss: 0.1326 - val_accuracy: 0.9766\n",
            "Epoch 18/50\n",
            "40408/40408 [==============================] - 31s 767us/step - loss: 0.2221 - accuracy: 0.9746 - val_loss: 0.3547 - val_accuracy: 0.9595\n",
            "Epoch 19/50\n",
            "40408/40408 [==============================] - 31s 768us/step - loss: 0.0669 - accuracy: 0.9784 - val_loss: 0.1264 - val_accuracy: 0.9639\n",
            "Epoch 20/50\n",
            "40408/40408 [==============================] - 31s 768us/step - loss: 0.0427 - accuracy: 0.9809 - val_loss: 0.0955 - val_accuracy: 0.9751\n",
            "Epoch 21/50\n",
            "40408/40408 [==============================] - 31s 770us/step - loss: 0.0391 - accuracy: 0.9815 - val_loss: 0.1406 - val_accuracy: 0.9610\n",
            "Epoch 22/50\n",
            "40408/40408 [==============================] - 31s 769us/step - loss: 0.0412 - accuracy: 0.9796 - val_loss: 1.1902 - val_accuracy: 0.8523\n",
            "Epoch 23/50\n",
            "40408/40408 [==============================] - 31s 768us/step - loss: 0.0977 - accuracy: 0.9765 - val_loss: 0.1001 - val_accuracy: 0.9782\n",
            "Epoch 24/50\n",
            "40408/40408 [==============================] - 31s 772us/step - loss: 0.1119 - accuracy: 0.9767 - val_loss: 0.6473 - val_accuracy: 0.9314\n",
            "Epoch 25/50\n",
            "40408/40408 [==============================] - 31s 775us/step - loss: 0.0765 - accuracy: 0.9758 - val_loss: 0.1858 - val_accuracy: 0.9535\n",
            "Epoch 26/50\n",
            "40408/40408 [==============================] - 31s 771us/step - loss: 0.0407 - accuracy: 0.9796 - val_loss: 0.1571 - val_accuracy: 0.9552\n",
            "Epoch 27/50\n",
            "40408/40408 [==============================] - 31s 768us/step - loss: 0.1119 - accuracy: 0.9774 - val_loss: 0.4088 - val_accuracy: 0.9307\n",
            "Epoch 28/50\n",
            "40408/40408 [==============================] - 31s 769us/step - loss: 0.0568 - accuracy: 0.9784 - val_loss: 0.1693 - val_accuracy: 0.9630\n",
            "Epoch 29/50\n",
            "40408/40408 [==============================] - 31s 768us/step - loss: 0.0813 - accuracy: 0.9767 - val_loss: 0.1103 - val_accuracy: 0.9737\n",
            "Epoch 30/50\n",
            "40408/40408 [==============================] - 31s 766us/step - loss: 0.0471 - accuracy: 0.9794 - val_loss: 0.1282 - val_accuracy: 0.9666\n",
            "Epoch 31/50\n",
            "40408/40408 [==============================] - 31s 767us/step - loss: 0.0387 - accuracy: 0.9796 - val_loss: 0.2095 - val_accuracy: 0.9403\n",
            "Epoch 32/50\n",
            "40408/40408 [==============================] - 31s 767us/step - loss: 0.2343 - accuracy: 0.9758 - val_loss: 0.2464 - val_accuracy: 0.9537\n",
            "Epoch 33/50\n",
            "40408/40408 [==============================] - 31s 772us/step - loss: 0.0595 - accuracy: 0.9788 - val_loss: 0.1151 - val_accuracy: 0.9693\n",
            "Epoch 34/50\n",
            "40408/40408 [==============================] - 31s 766us/step - loss: 0.0473 - accuracy: 0.9803 - val_loss: 0.8698 - val_accuracy: 0.9056\n",
            "Epoch 35/50\n",
            "40408/40408 [==============================] - 31s 771us/step - loss: 0.0892 - accuracy: 0.9762 - val_loss: 0.1694 - val_accuracy: 0.9575\n",
            "Epoch 36/50\n",
            "40408/40408 [==============================] - 31s 764us/step - loss: 0.1535 - accuracy: 0.9744 - val_loss: 0.3298 - val_accuracy: 0.9352\n",
            "Epoch 37/50\n",
            "40408/40408 [==============================] - 31s 764us/step - loss: 0.0558 - accuracy: 0.9788 - val_loss: 0.1502 - val_accuracy: 0.9630\n",
            "Epoch 38/50\n",
            "40408/40408 [==============================] - 31s 762us/step - loss: 0.0523 - accuracy: 0.9795 - val_loss: 0.1821 - val_accuracy: 0.9519\n",
            "Epoch 39/50\n",
            "40408/40408 [==============================] - 31s 763us/step - loss: 0.1064 - accuracy: 0.9763 - val_loss: 0.3745 - val_accuracy: 0.9196\n",
            "Epoch 40/50\n",
            "40408/40408 [==============================] - 31s 763us/step - loss: 0.0665 - accuracy: 0.9770 - val_loss: 0.1907 - val_accuracy: 0.9481\n",
            "Epoch 41/50\n",
            "40408/40408 [==============================] - 31s 762us/step - loss: 0.0461 - accuracy: 0.9803 - val_loss: 0.5953 - val_accuracy: 0.9657\n",
            "Epoch 42/50\n",
            "40408/40408 [==============================] - 31s 763us/step - loss: 0.1464 - accuracy: 0.9755 - val_loss: 0.2351 - val_accuracy: 0.9428\n",
            "Epoch 43/50\n",
            "40408/40408 [==============================] - 31s 767us/step - loss: 0.0419 - accuracy: 0.9796 - val_loss: 0.2704 - val_accuracy: 0.9303\n",
            "Epoch 44/50\n",
            "40408/40408 [==============================] - 31s 763us/step - loss: 0.0354 - accuracy: 0.9813 - val_loss: 0.2164 - val_accuracy: 0.9445\n",
            "Epoch 45/50\n",
            "40408/40408 [==============================] - 31s 767us/step - loss: 0.1299 - accuracy: 0.9778 - val_loss: 0.2056 - val_accuracy: 0.9510\n",
            "Epoch 46/50\n",
            "40408/40408 [==============================] - 31s 763us/step - loss: 0.0766 - accuracy: 0.9780 - val_loss: 0.7806 - val_accuracy: 0.9612\n",
            "Epoch 47/50\n",
            "40408/40408 [==============================] - 31s 763us/step - loss: 0.0959 - accuracy: 0.9758 - val_loss: 0.2065 - val_accuracy: 0.9661\n",
            "Epoch 48/50\n",
            "40408/40408 [==============================] - 31s 765us/step - loss: 0.0483 - accuracy: 0.9796 - val_loss: 0.1670 - val_accuracy: 0.9474\n",
            "Epoch 49/50\n",
            "40408/40408 [==============================] - 31s 764us/step - loss: 0.0365 - accuracy: 0.9807 - val_loss: 0.2269 - val_accuracy: 0.9323\n",
            "Epoch 50/50\n",
            "40408/40408 [==============================] - 31s 763us/step - loss: 0.1820 - accuracy: 0.9744 - val_loss: 0.1625 - val_accuracy: 0.9546\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7efd92175b38>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZajXEAwMVeF",
        "colab_type": "code",
        "outputId": "2170a08f-eb9f-4b02-b948-e10323d6eceb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 454
        }
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding_1 (Embedding)      (None, 4311, 100)         5000100   \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 4311, 100)         400       \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4311, 100)         0         \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 4307, 32)          16032     \n",
            "_________________________________________________________________\n",
            "max_pooling1d_1 (MaxPooling1 (None, 2153, 32)          0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 68896)             0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 2)                 137794    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 2)                 0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 2)                 6         \n",
            "=================================================================\n",
            "Total params: 5,154,332\n",
            "Trainable params: 5,154,132\n",
            "Non-trainable params: 200\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H7KQ_BGdRDk",
        "colab_type": "code",
        "outputId": "71baa8f2-bd15-4568-9c16-8d8655fdba6f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "prediction = model.predict(xx_val)\n",
        "\n",
        "\n",
        "c = confusion_matrix(y_val.argmax(axis=1), prediction.argmax(axis=1))\n",
        "print(c)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[2156  192]\n",
            " [  12 2130]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ZZV4cU4thGC",
        "colab_type": "code",
        "outputId": "25ca2080-9a9c-425c-a396-5e32d204d80d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix  \n",
        "y_pred = np.argmax(prediction, axis=1) \n",
        "\n",
        "print(precision_score(y_val.argmax(axis=1), y_pred , average=\"macro\")) \n",
        "print(recall_score(y_val.argmax(axis=1), y_pred , average=\"macro\")) \n",
        "print(f1_score(y_val.argmax(axis=1), y_pred , average=\"macro\"))\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9558888030740773\n",
            "0.9563130192451768\n",
            "0.9545641780241341\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8_dBJSYZJAtz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xx_val.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x2vgBuLaJECG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_val.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8w7nuL6SMT9x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xx_val"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S979IM922v4I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#start to prepare postprocessing data\n",
        "# reference: https://stackoverflow.com/questions/38674027/find-the-row-indexes-of-several-values-in-a-numpy-array\n",
        "import csv\n",
        "false_neg = open('false_neg.csv', 'w')\n",
        "false_list1 = xx_val[(y_val.argmax(axis=1) == 1) & (prediction.argmax(axis=1) == 0)] #False Negatives\n",
        "wr2 = csv.writer(false_neg, quoting=csv.QUOTE_ALL)\n",
        "\n",
        "out = np.where((xx_val==false_list1[:,None]).all(-1))[1]\n",
        "print(out)\n",
        "wr2.writerow(['index'])\n",
        "for x in out:\n",
        "  wr2.writerow([x])\n",
        "\n",
        "\n",
        "# for x in false_list1:\n",
        "#     print(x)\n",
        "#     wr2.writerow([x])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ragn5WZ44g50",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import csv\n",
        "#import numpy_indexed as npi\n",
        "false_pos = open('false_pos.csv', 'w')\n",
        "false_list2 = xx_val[(y_val.argmax(axis=1) == 0) & (prediction.argmax(axis=1) == 1)] #False Positives\n",
        "wr3 = csv.writer(false_pos, quoting=csv.QUOTE_ALL)\n",
        "\n",
        "# dims = xx_val.max(0)+1\n",
        "# out2 = np.where(np.in1d(np.ravel_multi_index(xx_val.T,dims),\n",
        "#                         np.ravel_multi_index(false_list2.T,dims)))[0]\n",
        "\n",
        "#result = npi.indices(xx_val, searched_values)\n",
        "# dims = xx_val.max(0)+1\n",
        "# X1D = np.ravel_multi_index(xx_val.T,dims)\n",
        "# searched_valuesID = np.ravel_multi_index(false_list2.T,dims)\n",
        "# sidx = X1D.argsort()\n",
        "# out2 = sidx[np.searchsorted(X1D,searched_valuesID,sorter=sidx)]\n",
        "#out2 = np.where((xx_val==false_list2[:,None]).all(-1))[1]\n",
        "result = [[i for i,row in enumerate(xx_val) if (s==row).all()] for s in false_list2]\n",
        "for x in result:\n",
        "  if(len(x)==2):\n",
        "    del x[1]\n",
        "wr3.writerow(['index'])\n",
        "for x in result:\n",
        "   wr3.writerow(x)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
